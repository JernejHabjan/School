{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naivni Bayesov klasifikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Orange.data import Table\n",
    "from Orange.data.filter import SameValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer za ogrevanje\n",
    "\n",
    "V letniku športne gimnazije imamo 20 učencev. Vsak od njih sodeluje pri enem od športov: ```kosarka```, ```nogomet```, ```gimnastika```. Njihovo višino smo ocenili \"na oko\" in vsakemu učencu pripisali eno od možnih vrednosti: ```nizek```, ```srednji``` ali ```visok```.\n",
    "\n",
    "<img src=\"footballers.png\" width=600/>\n",
    "\n",
    "<br/>\n",
    "<font color=\"blue\"> Kako bi novemu učencu Marku, ki je ```srednje``` rasti predlagali najprimernejši šport? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[visina | sport]\n",
      "[[visok | kosarka],\n",
      " [visok | kosarka],\n",
      " [visok | kosarka],\n",
      " [visok | kosarka],\n",
      " [srednji | kosarka],\n",
      " [srednji | kosarka],\n",
      " [nizek | kosarka],\n",
      " [visok | kosarka],\n",
      " [srednji | nogomet],\n",
      " [srednji | nogomet],\n",
      " [srednji | nogomet],\n",
      " [visok | nogomet],\n",
      " [visok | nogomet],\n",
      " [nizek | nogomet],\n",
      " [nizek | nogomet],\n",
      " [nizek | gimnastika],\n",
      " [nizek | gimnastika],\n",
      " [nizek | gimnastika],\n",
      " [srednji | gimnastika],\n",
      " [srednji | gimnastika]\n"
     ]
    }
   ],
   "source": [
    "data = Table(\"sportniki.tab\")\n",
    "print(data.domain)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za začetek poglejmo kako popularni so posamezni športi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport (Y): gimnastika, število: 5, verjetnost P(Y): 0.250000\n",
      "Sport (Y): kosarka, število: 8, verjetnost P(Y): 0.400000\n",
      "Sport (Y): nogomet, število: 7, verjetnost P(Y): 0.350000\n"
     ]
    }
   ],
   "source": [
    "for sport in data.domain[\"sport\"].values:\n",
    "    subset = SameValue(data.domain[\"sport\"], sport)(data)\n",
    "    py     = len(subset) / len(data)\n",
    "    print(\"Sport (Y): %s, število: %d, verjetnost P(Y): %f\" % (sport, len(subset), py))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/>\n",
    "<br/>\n",
    "Najpopularnejši šport je košarka, s katerim se ukvarja 8 oz. 40% učencev. Naš prvi predlog je torej, naj se Marko ukvarja s košarko. S tem rezultatom nismo najbolj zadovoljni, saj vidimo da med košarkaši ni veliko športnikov ```srednje``` višine. Razlog? Pri izračunu nismo upoštevali verjetnosti lastnosti oz. <i>atributa</i> o Markovi višini.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<div style=\"background-color:#00ccff; margin-left:50px; margin-right:50px\"> Splošnim verjetnostmi razredov, ki smo jih izračunali pravimo <i>apriorne</i> verjetnosti.\n",
    "\n",
    "Označimo jih z $P(Y)$, kjer je $Y$ spremenljivka razreda.\n",
    "</div>\n",
    "\n",
    "V našem primeru $Y$ zavzame vrednostmi {```kosarka```, ```nogomet```, ```gimnastika```}.\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport (Y): gimnastika, št. srednje visokih: 2, verjetnost P(X=srednji|Y=gimnastika): 0.400000\n",
      "Sport (Y): kosarka, št. srednje visokih: 2, verjetnost P(X=srednji|Y=kosarka): 0.250000\n",
      "Sport (Y): nogomet, št. srednje visokih: 3, verjetnost P(X=srednji|Y=nogomet): 0.428571\n"
     ]
    }
   ],
   "source": [
    "for sport in data.domain[\"sport\"].values:\n",
    "    subset_y = SameValue(data.domain[\"sport\"],   sport)(data)\n",
    "    subset_x = SameValue(data.domain[\"visina\"], \"srednji\")(subset_y)\n",
    "    p_xy = len(subset_x) / len(subset_y)\n",
    "    \n",
    "    print(\"Sport (Y): %s, št. srednje visokih: %d, verjetnost P(X=srednji|Y=%s): %f\" % (sport, len(subset_x), sport, p_xy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/>\n",
    "Zanimivo! Verjetnost ```srednje``` višine je največja med nogometaši. Ali podatek zadošča za spremembo prvotne odločitve?\n",
    "\n",
    "<br/>\n",
    "<div style=\"background-color:#00ccff; margin-left:50px; margin-right:50px\">\n",
    "Verjetnosti $P(X|Y)$ pravimo <i>pogojna verjetnost spremenljivke $X$ pri znanem $Y$</i>.  Opredeljuje verjetnost, da je v primerih razreda $Y$ atribut $X$ zavzame določeno vrednost. \n",
    "</div>\n",
    "\n",
    "Katera verjetnost pa nas v resnici zanima? Želimo, da izračun upošteva Markovo višino in oceni verjetnost vsakega od športov. To je verjetnost\n",
    "\n",
    "$$ P(Y|X) $$\n",
    "\n",
    "oz. v Markovem primeru\n",
    "\n",
    "$$ P(Y|X=srednji)$$\n",
    "\n",
    "Za izračun te verjetnosti uporabimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesov obrazec\n",
    "\n",
    "Da bi izračunali verjetno razreda pri danih atributih $P(Y|X)$, potrebujemo verjetnost za vse možne kombinacije razreda $Y$ in atributov $X$, ki jo označimo z $P(X, Y)$. Iz pravil o pogojni verjetnosti sledi:\n",
    "\n",
    "$$ P(X, Y) = P(X|Y) \\cdot P(Y) = P(Y|X) \\cdot P(X)$$ \n",
    "\n",
    "<br/>\n",
    "<div style=\"background-color:#00ccff; margin-left:50px; margin-right:50px\">\n",
    "Iz česar sledi <i>Bayesov obrazec</i> za izračun $P(Y|X)$:\n",
    "\n",
    "$$P(Y|X) = \\frac{P(X|Y) \\cdot P(Y)}{P(X)} $$ \n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "Izračun verjetnosti razreda $Y$ pri znanih atributih $X$ je torej odvisen od apriorne verjetnosti razreda $P(Y)$, pogojne verjetnosti $P(X|Y)$ in apriorne verjetnosti atributov $P(X)$. <font color=\"blue\">V Markovem primeru torej:</font>\n",
    "\n",
    "$$P(Y|X=srednji) = \\frac{P(X=srednji|Y) \\cdot P(Y)}{P(X=srednji)} $$ \n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "Če verjetnost ocenimo za vsako možno vrednost razreda Y, torej {```kosarka```, ```nogomet```, ```gimnastika```}, dobimo odgovor na prvotno vprašanje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sport (Y): gimnastika, napoved P(Y=gimnastika | X=srednji): 0.285714\n",
      "Sport (Y): kosarka, napoved P(Y=kosarka | X=srednji): 0.285714\n",
      "Sport (Y): nogomet, napoved P(Y=nogomet | X=srednji): 0.428571\n"
     ]
    }
   ],
   "source": [
    "for sport in data.domain[\"sport\"].values:\n",
    "    \n",
    "    subset_y  = SameValue(data.domain[\"sport\"],   sport)(data)        # vsi sportniki danega sporta\n",
    "    subset_x  = SameValue(data.domain[\"visina\"], \"srednji\")(data)     # vsi srednje visoki ucenci\n",
    "    \n",
    "    subset_xy = SameValue(data.domain[\"visina\"], \"srednji\")(subset_y) # vsi srednje visoki ucenci v danem sportu\n",
    "    \n",
    "    # Izracunamo verjetnosti\n",
    "    p_y  = len(subset_y)  / len(data)         \n",
    "    p_x  = len(subset_x)  / len(data)\n",
    "    p_xy = len(subset_xy) / len(subset_y)\n",
    "    \n",
    "    p_yx = (p_xy * p_y) / p_x\n",
    "    \n",
    "    print(\"Sport (Y): %s, napoved P(Y=%s | X=srednji): %f\" % (sport, sport, p_yx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacija Naivnega Bayesovega klasifikatorja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Naivni Bayesov klasifikator</i> predpostavlja, da so atributi neodvisni med seboj, pri znanem razredu.\n",
    "\n",
    "$$ P(Y|X_1, X_2, ..., X_p) = \\frac{P(Y) \\cdot P(X_1|Y) \\cdot P(X_2|Y) \\cdots P(X_p|Y)}{P(X)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Naredi sam/a.</b></font> Dopolni implementacijo naivnega Bayesovega klasifikatorja, ki je definiran v spodnjem odseku. Dopolniti je potrebno del kode, kjer izračunamo \n",
    "* verjetnostne porazdelitev razredov $P(Y)$\n",
    "* verjetnostne porazdelitve atributov pri znanem razredu $P(X|Y)$\n",
    "\n",
    "\n",
    "\n",
    "#### Sklepanje o podatkih\n",
    "\n",
    "V primeru diskretnih atributov lahko obe porazdelitvi dobimo s <i>preštevanjem</i>.\n",
    "* $P(Y)$ <i> Kolikokrat se v podatkih pojavi razred $Y$?</i>\n",
    "* $P(X|Y)$ <i> Kolikokrat se v podatkih, ki spadajo v razred $Y$, pojavi atribut $X$?</i>\n",
    "\n",
    "\n",
    "<font color=\"blue\"><b>Kaj pa $P(X)$?</b></font> To verjetnost je včasih težko izračunljiva, posebej pri visoko dimenzionalnih podatkih, saj ni nujno, da bodo v podatki prisotne vse kombinacije atributov. Na srečo ta vrednost ne vpliva na izbiro najverjetnejšega razreda za posamezen primer!\n",
    "\n",
    "#### Napovedovanje\n",
    "\n",
    "Z nov primer $X^* = (X_1^*, X_2^*, ..., X_p^*)$ med vsemi vrednosti razreda $Y=y$, izberi tisto, ki maksimizira naslednji izraz:\n",
    "\n",
    "\n",
    "$$ \\text{arg max}_y \\ P(Y=y) \\cdot P(X_1^*|Y=y) \\cdot P(X_2^*|Y=y) \\cdots P(X_p^*|Y=y) $$\n",
    "\n",
    "#### Log-transformacija\n",
    "\n",
    "Težava pri zgornjem pristopu pre praktične narave; množenje velikega števila verjetnosti hitro privede do zelo majhnih števil, ki lahko presežejo strojno natančnost. Najenostavnejša rešitev, ki vede do enake izbire razreda je naslednja \n",
    "\n",
    "$$ \\text{arg max}_y \\ \\text{log } P(Y=y) + \\text{log } P(X_1|Y=y) + \\text{log } P(X_2|Y=y) + ... + \\text{log } P(X_p|Y=y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri implementaciji si pomagaj s podatki potnikov ladje <i><a href=\"https://www.kaggle.com/c/titanic\">Titanic</a></i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived\n",
      "['no', 'yes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[crew, adult, male | yes],\n",
       " [crew, adult, male | no],\n",
       " [third, adult, male | no],\n",
       " [crew, adult, male | no],\n",
       " [crew, adult, female | yes],\n",
       " ...\n",
       "]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Table(\"titanic-training.tab\")\n",
    "print(data.domain.class_var)\n",
    "print(data.domain.class_var.values)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Naive Bayes classifier.\n",
    "    \n",
    "\n",
    "    :attribute self.probabilities\n",
    "        Dictionary that stores\n",
    "            - prior class probabilities P(Y)\n",
    "            - attribute probabilities conditional on class P(X|Y)\n",
    "    \n",
    "    :attribute self.class_values\n",
    "        All possible values of the class.\n",
    "        \n",
    "    :attribute self.variables\n",
    "        Variables in the data. \n",
    "    \n",
    "    :attribute self.trained\n",
    "        Set to True after fit is called.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trained       = False\n",
    "        self.probabilities = dict()   \n",
    "    \n",
    "    \n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit a NaiveBayes classifier.\n",
    "        \n",
    "        :param data\n",
    "            Orange data Table.        \n",
    "        \"\"\"\n",
    "        class_variable      = data.domain.class_var    # class variable (Y) \n",
    "        self.class_values   = class_variable.values    # possible class values\n",
    "        self.variables      = data.domain.variables    # all other variables (X)\n",
    "        \n",
    "        n = len(data) # number of all data points\n",
    "        \n",
    "        # Compute P(Y)\n",
    "        for y in self.class_values:\n",
    "\n",
    "            # A not too smart guess (INCORRECT)\n",
    "            self.probabilities[y] = 1/len(self.class_values)\n",
    "            \n",
    "            # <your code here>\n",
    "            # Compute class probabilities and correctly fill\n",
    "            #   probabilities[y] = ... \n",
    "            # Select all examples (rows) with class = y\n",
    "          \n",
    "            # </your code here>\n",
    "        \n",
    "        # Compute P(X|Y)\n",
    "        for y in self.class_values:\n",
    "            \n",
    "            # Select all examples (rows) with class = y\n",
    "            filty = SameValue(class_variable, y)\n",
    "            \n",
    "            for variable in self.variables:\n",
    "                for x in variable.values:\n",
    "                    \n",
    "                    # A not too smart guess (INCORRECT)\n",
    "                    p = 1 / (len(self.variables) * len(variable.values) * len(self.class_values))\n",
    "                    self.probabilities[variable, x, y] = p\n",
    "                    \n",
    "                \n",
    "                    # <your code here>\n",
    "                    # Compute correct conditional class probability\n",
    "                    #   probabilities[x, value, c] = ... \n",
    "                    # \n",
    "                    # Select all examples with class == y AND \n",
    "                    # variable x == value\n",
    "                    # Hint: use SameValue filter twice\n",
    "                \n",
    "                    \n",
    "                \n",
    "                    # </your code here>\n",
    "    \n",
    "        self.trained = True\n",
    "        \n",
    "    \n",
    "    def predict_instance(self, row):\n",
    "        \"\"\"\n",
    "        Predict a class value for one row.\n",
    "        \n",
    "        :param row\n",
    "            Orange data Instance.\n",
    "        :return \n",
    "            Class prediction.\n",
    "        \"\"\"\n",
    "        curr_p = float(\"-inf\")   # Current highest \"probability\" (unnormalized)\n",
    "        curr_c = None            # Current most probable class\n",
    "        \n",
    "        for y in self.class_values:\n",
    "            p = np.log(self.probabilities[y])\n",
    "            for x in self.variables:\n",
    "                p = p + np.log(self.probabilities[x, row[x].value, y])\n",
    "            \n",
    "            if p > curr_p:\n",
    "                curr_p = p\n",
    "                curr_c = y\n",
    "                \n",
    "        return curr_c, curr_p\n",
    "        \n",
    "   \n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Predict class labels for all rows in data.\n",
    "        \n",
    "        :param data\n",
    "            Orange data Table.       \n",
    "        :return y\n",
    "            NumPy vector with predicted classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        n = len(data)\n",
    "        predictions = list()\n",
    "        confidences = np.zeros((n, ))\n",
    "        \n",
    "        for i, row in enumerate(data):\n",
    "            pred, cf = self.predict_instance(row)\n",
    "            predictions.append(pred)\n",
    "            confidences[i] = cf\n",
    "    \n",
    "        return predictions, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Uporaba klasifikatorja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer uporabe na podatkih potnikov ladje <i><a href=\"https://www.kaggle.com/c/titanic\">Titanic</a></i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NaiveBayes()\n",
    "model.fit(data)\n",
    "model.probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, confidences = model.predict(data)\n",
    "\n",
    "for row, p, c in zip(data, predictions, confidences):\n",
    "    print(\"Row=%s, predicted class=%s confidence=%.5f\" % (row, p, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ocenjevanje uspešnosti klasifikacije\n",
    "\n",
    "Za ocenjevanje uspešnosti klasifikacije vsak napovedani primer primerjamo s pripadajočim resničnim razredo. Štirje možni izidi primerjave so naslednji: \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<ul>\n",
    "<li>TP: True positives (pravilno napovedani pozitivni primeri)</li>\n",
    "<li>FP: False positives (napačno napovedani negativni primeri)</li>\n",
    "<li>TN: True negatives (pravilno napovedani negativni primeri)</li>\n",
    "<li>FN: False negatives (napačno napovedani pozitini primeri)</li>\n",
    "</ul> \n",
    "\n",
    "<br/>\n",
    "<img src=\"type12_error.jpeg\" width=400/>\n",
    "\n",
    "</td>\n",
    "<td><img width=\"400\" src=\"Precisionrecall.png\"></img><td>\n",
    "<tr/>\n",
    "<table>\n",
    "\n",
    "\n",
    "#### Delež pravilno razvrščenih razredov (ang. classification accuracy)\n",
    "\n",
    "\n",
    "$$ca = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "<font color=\"green\">Prednosti</font>:\n",
    "* Enostaven izračun, jasna interpretacija\n",
    "* Uporabna mera za poljubno število razredov\n",
    "\n",
    "<font color=\"red\">Slabosti</font>:\n",
    "* Lahko zavaja pri neuravnoteženih porazdelitvah razredov\n",
    "\n",
    "<br/>\n",
    "\n",
    "#### Natančnost, priklic (ang. precision, recall)\n",
    "\n",
    "\n",
    "\n",
    "$$ p = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "$$ r = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "<font color=\"green\">Prednosti</font>:\n",
    "* Enostaven izračun, jasna interpretacija\n",
    "* Ločitev obeh tipov napak (napačno pozitivni in napačno negativni primeri)\n",
    "* Uporabna tudi pri neuravnoteženih porazdelitvah razredov\n",
    "\n",
    "<font color=\"red\">Slabosti</font>:\n",
    "* Uporabno pretežno za klasifikacijo v dva razreda\n",
    "* Težko povzeti obe meri ; približek je F1-vrednost (ang. F1-score)\n",
    "$$ F1 = 2 \\frac{p \\cdot r}{p + r} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Naredi sam/a.</b></font> Napovej razrede na testni množici. Napovedane razrede primerjaj z resničnimi in izmeri klasifikacijsko točnost, natančnost, priklic in F1-vrednost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# uporaba metod: \n",
    "test_data      = Table(\"titanic-test.tab\")\n",
    "predictions, _ = model.predict(test_data) \n",
    "truth          = [row[\"survived\"].value for row in test_data]\n",
    "accuracy_score(truth, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\"><b>Izziv.</b></font> Nekateri atributi imajo verjetnost 0 pri posameznem razredu. Kako bi popravili klasifikator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"><b>Razmisli.</b></font> Kako bi dopolnili klasifikator, če bi bili nekateri atributi lahko tudi zvezni? Namig: spomni se vaj, ko smo spoznali <i>verjetnostne porazdelitve</i> zveznih spremenljivk. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
