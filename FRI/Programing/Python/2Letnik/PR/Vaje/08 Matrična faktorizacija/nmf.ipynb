{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nenegativna matrična faktorizacija in priporočilni sistemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sedaj smo obravnavali modele, ki so iz <i>več neodvisnih</i> napovedovali <i>eno</i> odvisno spremenljivko. V scenariju priporočilnega sistema smo tako za vsakega uporabnika zgradili svoj model.\n",
    "\n",
    "Glavna motivacija metod za priporočilne sisteme je, da modeli uporabnikov med sabo <i>niso neodvisni</i>. Želimo enoten model, ki bo ovrednotil poljubno kombinacijo uporabnika in izdelka, ter implicinto izkoriščal medsebojno informacijo med različnimi modeli uporabnikov. \n",
    "\n",
    "Eden od modelov, ki se zelo pogosto uporabljajo v praksi je model matrične faktorizacija.\n",
    "Ta predpostavlja matriko uporabnikov in izdelkov, ki ji predstavimo kot produkt dveh matrik <i>nižjega ranga</i>. Slednja lastnost omogoča stiskanje informacije in sklepanje o novih (ne-videnih, manjkajočih vrednosti) v izvirni matriki.\n",
    "\n",
    "<img width=450 src=\"nmf-shema-01.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uvodne definicije\n",
    "\n",
    "Matriko podatkov $\\mathbf{X}$, ki vsebuje manjkajoče vrednosti, z modelom matrične faktorizacije predstavimo na naslednji način:\n",
    "$$ \\mathbf{X} = \\mathbf{W} \\mathbf{H}^T + \\mathbf{E} $$,\n",
    "\n",
    "torej kot produkt matrike $\\mathbf{W}$, ki predstavlja prostor vrstic, $\\mathbf{H}$ predstavlja prostor stolpcev, $\\mathbf{E}$ pa ostanek oz. napako. Matriki $\\mathbf{W}, \\mathbf{H}$ si včasih predstavljamo kot hkratno gručenje stolpcev in vrstic. Matrike so naslednjih velikosti:\n",
    "$$ \\mathbf{X} \\in \\mathbb{R}^{m \\times n}, \\mathbf{W} \\in \\mathbb{R}^{m \\times r}, \\mathbf{H} \\in \\mathbb{R}^{n \\times r},  \\mathbf{E} \\in \\mathbb{R}^{m \\times n}$$\n",
    "\n",
    "Predostavljamo, da sta matriki $\\mathbf{W}, \\mathbf{H}$ <i>nizkega ranga</i>, kar v praksi pomeni da celotno informacijo iz $\\mathbf{X}$ predstavljamo v stisnjeni obliki, torej\n",
    "$$r < m, r < n $$.\n",
    "\n",
    "Predpostavljamo tudi, da so matrike $\\mathbf{X}$, $\\mathbf{W}$ in $\\mathbf{H}$ nenegativne. Tedaj govorimo o <b>nenegativni matrični faktorizaciji (NMF)</b>.\n",
    "$$x_{i, j} > 0, w_{i, k} > 0, h_{j, k} > 0, \\forall i, j, k $$.\n",
    "\n",
    "Matrika napake $\\mathbf{E}$ te omejitve nima (<font color=\"blue\">razmisli</font>: zakaj?).\n",
    "\n",
    "<br/>\n",
    "### Definicija problema\n",
    "\n",
    "Želimo torej poiskati matriki $\\mathbf{W}$ in $\\mathbf{H}$, tako da vrednost napake karseda nizka. To lahko zapišemo kot naslednji optimizacijski problem:\n",
    "\n",
    "$$ \\text{min}_{\\mathbf{W},\\mathbf{H}}\\ \\| \\mathbf{X} - \\mathbf{W}\\mathbf{H}^T \\|_F^2 = \\text{min}_{\\mathbf{W},\\mathbf{H}}\\ J$$\n",
    "\n",
    "Oznaka $\\| \\mathbf{A} \\|_F = \\sqrt{\\sum_{i,j} a_{i,j}^2}$ predstavlja <i>Frobeniusovo normo</i> matrike $\\mathbf{A}$.  (<font color=\"blue\">razmisli</font>: Opaziš podobnost s srednjo kvadratično napako, ki smo jo spoznali v kontekstu linearne regresije?)\n",
    "\n",
    "\n",
    "Vrednost $J$ imenujemo <i>kriterijska funkcija</i>, problem iskanja minimuma pa <i>optimizacijski oz. minimizacijski problem</i>.  <b>Posebnost</b> priporičilnih sistemov je ta, da napako računamo samo na vrednostih v $\\mathbf{X}$, ki so znane. Kriterijska funkcija je torej:\n",
    "\n",
    "$$ J = \\sum_{i, j | x_{i,j} \\not = 0} (x_{i, j} - \\sum_{l=1}^{r} w_{i,l}h_{j, l} )^2 $$\n",
    "\n",
    "Za ta konkreten problem velja, da nima globalno optimalne rešitve za spremenljivke $\\mathbf{W},\\mathbf{H}$.  Vseeno ga lahko rešimo npr. z odvajanjem kriterijske funkcije in premikanjem v negativni smeri gradienta. Dobimo \n",
    "<i>pravila za posodabljanje</i> vrednosti v $\\mathbf{W},\\mathbf{H}$:\n",
    "\n",
    "Vse vrednosti $w_{i,k}$ in $h_{j, k}$ popravimo tako, da vrednost v prejšnji iteraciji <i>popravimo</i> v negativni smeri gradienta, s <i>korakom</i> $\\eta$:\n",
    "\n",
    "$$ w_{i,k}^{(t+1)}  = w_{i, k}^{(t)} - \\eta \\frac{\\delta J}{\\delta w_{i,k}} = w_{i, k}^{(t)} + \\eta \\sum_{j \\ | \\ x_{i,j} \\not = 0} (x_{i,j} - \\sum_{l=1}^r w_{i,l} h_{j, l})(w_{i, k}^{(t)})$$\n",
    "\n",
    "$$ h_{j, k}^{(t+1)}  = h_{j, k}^{(t)} - \\eta \\frac{\\delta J}{\\delta h_{j, k}} = h_{j, k}^{(t)} + \\eta \\sum_{i \\ | \\  x_{i,j} \\not = 0} (x_{i,j} - \\sum_{l=1}^r w_{i,l} h_{j, l})(h_{j, k}^{(t)})$$\n",
    "\n",
    "<font color=\"green\"><b>Pravila izpeljemo na tablo.</b></font>\n",
    "\n",
    "\n",
    "<br/>\n",
    "### Stohastični gradientni sestop\n",
    "\n",
    "Stohastični gradientni sestop (SGD) je postopek za reševanje optimizcijskih problemov, ki niso globalno rešljivi, za vse nastopajoče spremenljivke (v našem primeru vse $w_{i,k}$ in $h_{j, k}$) pa znamo izračunati odvod glede na kriterijsko funkcijo. To smo storili v prešnjem delu.\n",
    "Postopek za iskanje <i>lokalnega minimuma</i> je naslednji.\n",
    "\n",
    "1. Naključno nastavi vrednosti vseh spremenljivk  $w_{i,k}$ in $h_{j, k}$. V našem primeru \n",
    "    velja $w_{i,k} > 0$  in $h_{j, k} > 0$.\n",
    "2. V iteraciji $t = 1...T$:\n",
    "    \n",
    "    2.1 V naključnem vrstnem redu posodabljaj $\\forall i, k, j$\n",
    "$$ w_{i,k}^{(t+1)}  = w_{i, k}^{(t)} - \\eta \\frac{\\delta J}{\\delta w_{i,k}} $$\n",
    "$$ h_{j, k}^{(t+1)}  = h_{j, k}^{(t)} - \\eta \\frac{\\delta J}{\\delta h_{j, k}} $$\n",
    "            \n",
    "<img width=450 src=\"gradient-descent-1.png\"/>\n",
    "Shematski prikaz gradientnega sestopa za hipotetični spremenljivki $w$, $h$ in kriterijsko funkcijo $J(w, h)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Naredi sam/a.</b></font> Dopolni spodnjo implementacijo algoritma NMF, tako da uporabiš posodobitvena pravila v več iteracijah stohastičnega gradientnega sestopa. \n",
    "<br/>\n",
    "<font color=\"blue\"><b>Namig.</b></font> Pri računanju gradienta upoštevaj samo vrednosti $x_{i, j}$, ki so znane (različne od 0). Za učinkovito implementacijo izračuna vsot $\\sum_{i \\ | \\  x_{i,j} \\not = 0} $ in $\\sum_{j \\ | \\  x_{i,j} \\not = 0} $ najprej (pred začetkom iteracij):\n",
    "* za vsako vrstico $i$ shranimo neničelne stolpce\n",
    "* za vsak stolpec $j$ shranimo neničelne vrstice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "class NMF:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit a matrix factorization model for a matrix X with missing values.\n",
    "    such that\n",
    "        X = W H.T + E \n",
    "    where\n",
    "        X is of shape (m, n)    - data matrix\n",
    "        W is of shape (m, rank) - approximated row space\n",
    "        H is of shape (n, rank) - approximated column space\n",
    "        E is of shape (m, n)    - residual (error) matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, rank=10, max_iter=100, eta=0.01):\n",
    "\n",
    "        \"\"\"\n",
    "        :param rank: Rank of the matrices of the model.\n",
    "        :param max_iter: Maximum nuber of SGD iterations.\n",
    "        :param eta: SGD learning rate.\n",
    "        \"\"\"\n",
    "        self.rank = rank\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "    \n",
    "    \n",
    "    def fit(self, X, verbose = False):\n",
    "        \"\"\"\n",
    "        Fit model parameters W, H.\n",
    "        :param X: \n",
    "            Non-negative data matrix of shape (m, n)\n",
    "            Unknown values are assumed to take the value of zero (0).\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "\n",
    "        W = np.random.rand(m, self.rank)\n",
    "        H = np.random.rand(n, self.rank)\n",
    " \n",
    "        # Indices to model variables\n",
    "        w_vars = list(itertools.product(range(m), range(self.rank)))\n",
    "        h_vars = list(itertools.product(range(n), range(self.rank)))\n",
    "\n",
    "        # Indices to nonzero rows/columns\n",
    "        nzcols = dict([(j, X[:, j].nonzero()[0]) for j in range(n)])\n",
    "        nzrows = dict([(i, X[i, :].nonzero()[0]) for i in range(m)])\n",
    "\n",
    "        # Errors\n",
    "        self.error = np.zeros((self.max_iter,))\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            t1 = time.time()\n",
    "            np.random.shuffle(w_vars)\n",
    "            np.random.shuffle(h_vars)\n",
    "\n",
    "            for i, k in w_vars:\n",
    "                wgrad   = sum([(X[i, j] - W[i, :].dot(H[j, :]))*W[i, k] for j in nzrows[i]])\n",
    "                W[i, k] = max(0, W[i, k] + self.eta * wgrad)\n",
    "\n",
    "            for j, k in h_vars:\n",
    "                hgrad   = sum([(X[i, j] - W[i, :].dot(H[j, :]))*H[j, k] for i in nzcols[j]])\n",
    "                H[j, k] = max(0, H[j, k] + self.eta * hgrad)\n",
    "            \n",
    "            self.error[t] = sum([sum([(X[i, j] - W[i, :].dot(H[j, :]))**2 for j in nzrows[i]]) \n",
    "                                for i in range(X.shape[0])])\n",
    "\n",
    "            if verbose:\n",
    "                print(t, self.error[t])\n",
    "       \n",
    "        self.W = W\n",
    "        self.H = H\n",
    "    \n",
    "    \n",
    "    def predict(self, i, j):\n",
    "        \"\"\"\n",
    "        Predict score for row i and column j\n",
    "        :param i: Row index.\n",
    "        :param j: Column index.\n",
    "        \"\"\"\n",
    "        return self.W[i, :].dot(self.H[:, j])\n",
    "    \n",
    "\n",
    "    def predict_all(self):\n",
    "        \"\"\"\n",
    "        Return approximated matrix for all\n",
    "        columns and rows.\n",
    "        \"\"\"\n",
    "        return self.W.dot(self.H.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testirajmo metodo na matriki naključnih podatkov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 100       # St. vrstic\n",
    "n = 80        # St. stolpcev\n",
    "rank = 5      # Rang model\n",
    "error = 0.1   # Nakljucni šum\n",
    "A = np.random.rand(m, rank*2)  \n",
    "B = np.random.rand(n, rank*2)\n",
    "X = A.dot(B.T) + error * np.random.rand(m, n)  # generiramo podatke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Poženemo iskanje parametrov $\\mathbf{W}$, $\\mathbf{H}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NMF(rank=rank, max_iter=20, eta=0.001)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napaka modela pada s številom iteracij."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x258d5213390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH1H2dXrYPe4aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x258d30620b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model.error)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primerjajmo model in izvirne podatke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].pcolor(X)\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].pcolor(model.predict_all())\n",
    "ax[1].set_title(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izračunamo pojasnjeno varianco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf00d1bc99a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexpl_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mXp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexpl_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "Xp = model.predict_all()\n",
    "expl_var = (np.var(X) - np.var(X-Xp))/np.var(X)\n",
    "expl_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Naredi sam/a.</b></font> Kako se pojasnjena varianca spreminja z rangom modela, št. iteracij?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.187299693284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.327841134178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.442006484819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.563454999532\n"
     ]
    }
   ],
   "source": [
    "for rank in range(3,7): ###rank povečujemo\n",
    "    model = NMF(rank=rank, max_iter=20, eta=0.001)\n",
    "    model.fit(X)\n",
    "\n",
    "    Xp = model.predict_all()\n",
    "    expl_var = (np.var(X) - np.var(X-Xp))/np.var(X)\n",
    "    print(rank, expl_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jester(p=0.05):\n",
    "    \"\"\"\n",
    "    :param p: Probability of rating appearing in the training set.\n",
    "    :return\n",
    "        X training grades (retining with probability p)\n",
    "        Y test grades (whole dataset) \n",
    "    \"\"\"\n",
    "\n",
    "    Y = np.genfromtxt(\"jester-data.csv\", delimiter=\",\", dtype=float, )\n",
    "    Y = Y[:, 1:]\n",
    "    Y[Y == 99] = 0 \n",
    "    Y[Y != 0]  = Y[Y!=0] + abs(Y[Y!=0].min())\n",
    "\n",
    "    # Separate data in test/train with probability p\n",
    "    M = np.random.rand(*Y.shape) \n",
    "    M_tr = M < p\n",
    "    M_te = M > p\n",
    "    X = Y * M_tr\n",
    "    Y = Y * M_te\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Naredi sam/a.</b></font> Preizkusi metodo NMF na podatkovni zbirki Jester. Podatki so razdeljeni na učno in testno množico, kjer je v učni množici prisoten delež $p$ ocen. Poženi model na učni množici in izračunaj testno napako (RMSE, pojasnjeno varianco) na ocenah, ki niso bile uporabljene za učenje. Izračunaj, kako se testna napaka spreminja v odvisnosti od:\n",
    "* delež učnih ocen $p$,\n",
    "* ranga matrik modela (število $r$, parameter ```rank```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "jester-data.csv not found.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3ab52d2a9656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# X: 1% podatkov, Y ostalih 99%------ 1 procent je premalo... zato so notri same nule... dal sem iz 0.01 na ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_jester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-8c41a67c0047>\u001b[0m in \u001b[0;36mload_jester\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jester-data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jernej Habjan\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                 \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jernej Habjan\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jernej Habjan\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_file_openers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: jester-data.csv not found."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Naložimo podatkovno zbirko Jester z 1% upoštevanih ocen\n",
    "from jester import load_jester\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X: 1% podatkov, Y ostalih 99%------ 1 procent je premalo... zato so notri same nule... dal sem iz 0.01 na ... \n",
    "X, Y = load_jester(p=0.10)\n",
    "X.shape\n",
    "\n",
    "model = NMF(rank=5, max_iter=10)\n",
    "model.fit(X, True)\n",
    "Yp = model.predict_all()\n",
    "expl_var = (np.var(Y) - np.var(Y-Yp))/np.var(Y)\n",
    "mse = mean_squared_error(Yp, Y)\n",
    "print(expl_var, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].pcolor(Y)\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "ax[1].pcolor(Yp)\n",
    "ax[1].set_title(\"Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}